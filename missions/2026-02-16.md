# üéØ ClawBoz Project Missions - 2026-02-16

**Today's hands-on projects:** 3 practical missions
**Sources:** Product Hunt, HackerNews, GitHub Trending, X, AI News
**Difficulty:** Mix of beginner to advanced

---

## Mission 1: Connect Claude to Gmail and Analyze Your Inbox Trends

**‚è±Ô∏è Time:** 30-45 minutes  
**üìä Difficulty:** Intermediate  
**üõ†Ô∏è Tools:** Claude Code, Python, Google Cloud Console

### üí° What You're Building

Build an MCP server that connects Claude to Gmail, analyzes your inbox patterns, and gives you insights about your communication habits.

**You'll have:**
- A working Gmail MCP server that Claude can query
- Analytics showing your top senders, response times, and email patterns
- Auto-categorization of emails (work, personal, newsletters, etc.)
- A dashboard showing your inbox health metrics

### ‚úÖ Prerequisites

- Gmail account
- Python 3.8+ installed
- Basic familiarity with terminal

### üöÄ Step-by-Step Instructions

**Execute these steps through Claude Code:**

#### Step 1: Set up Google Cloud Project

Create a Google Cloud project and enable Gmail API

```bash
# Go to https://console.cloud.google.com/
# Create new project: 'Claude-Gmail-MCP'
# Enable Gmail API from APIs & Services
# Create OAuth 2.0 credentials
# Download credentials.json to ~/ClawBoz/gmail-mcp/
```

**Success Checklist:**
- [ ] Google Cloud project created
- [ ] Gmail API enabled
- [ ] OAuth credentials downloaded

#### Step 2: Install MCP SDK and Dependencies

Set up Python environment with MCP SDK

```bash
mkdir -p ~/ClawBoz/gmail-mcp
cd ~/ClawBoz/gmail-mcp
python3 -m venv .venv
source .venv/bin/activate
pip install mcp google-auth-oauthlib google-auth-httplib2 google-api-python-client
```

**Success Checklist:**
- [ ] Virtual environment created
- [ ] MCP SDK installed
- [ ] Google API client libraries installed

#### Step 3: Build the Gmail MCP Server

Create server.py with Gmail integration

```bash
# Ask Claude Code to create server.py with:
# - MCP server setup using @modelcontextprotocol/sdk
# - Gmail authentication flow
# - Tools: list_emails, search_emails, get_email, analyze_inbox
# - Token caching for reuse
```

**Success Checklist:**
- [ ] server.py created with MCP server class
- [ ] Gmail authentication implemented
- [ ] At least 3 Gmail tools defined
- [ ] OAuth token caching works

#### Step 4: Register MCP Server with Claude

Add server to Claude's MCP configuration

```bash
# Edit ~/.claude/config.json or use Claude settings
# Add entry:
# {
#   "mcpServers": {
#     "gmail": {
#       "command": "python",
#       "args": ["/Users/home/ClawBoz/gmail-mcp/server.py"]
#     }
#   }
# }
# Restart Claude Code
```

**Success Checklist:**
- [ ] MCP server registered in config
- [ ] Claude Code restarted
- [ ] Gmail tools appear in Claude's tool list

#### Step 5: Test and Analyze Your Inbox

Use Claude to query and analyze your emails

```bash
# In Claude Code, try:
# 'Show me my top 10 email senders this month'
# 'Categorize my last 50 emails by type'
# 'What are my average email response times?'
# 'Find all unread emails from the last week'
```

**Success Checklist:**
- [ ] Successfully authenticated with Gmail
- [ ] Can list and search emails
- [ ] Analytics queries return results
- [ ] Dashboard or insights generated

### üéØ Success Criteria

- [ ] Claude can read your Gmail inbox through MCP
- [ ] You have analytics about your email patterns
- [ ] Server handles OAuth authentication properly
- [ ] You understand how MCP servers work

### üê∞ Next Steps (Optional)

Once you've completed the basics, try:

- Add email sending capability
- Implement smart filtering (spam detection, priority inbox)
- Create scheduled reports (daily digest)
- Build email templates and auto-responses

---

## Mission 2: Build an MCP Server to Pull Data from Multiple APIs

**‚è±Ô∏è Time:** 25-35 minutes  
**üìä Difficulty:** Beginner  
**üõ†Ô∏è Tools:** Claude Code, Python, MCP SDK

### üí° What You're Building

Create a unified MCP server that aggregates data from GitHub, HackerNews, and RSS feeds into Claude.

**You'll have:**
- Multi-source data aggregator MCP server
- Claude can query GitHub trends, HN top stories, and RSS feeds
- Unified search across all data sources
- Cached responses for faster queries

### ‚úÖ Prerequisites

- Python 3.8+ installed
- GitHub account (for API token)

### üöÄ Step-by-Step Instructions

**Execute these steps through Claude Code:**

#### Step 1: Create Project Structure

Set up the MCP server project

```bash
mkdir -p ~/ClawBoz/data-mcp
cd ~/ClawBoz/data-mcp
python3 -m venv .venv
source .venv/bin/activate
pip install mcp requests feedparser
touch server.py config.json
```

**Success Checklist:**
- [ ] Project directory created
- [ ] Virtual environment activated
- [ ] Dependencies installed

#### Step 2: Implement Data Source Connectors

Create functions to fetch from each API

```bash
# Ask Claude Code to create:
# - fetch_github_trending() - uses GitHub API
# - fetch_hackernews_top() - uses HN API
# - fetch_rss_feed(url) - parses any RSS feed
# All should return normalized JSON format
```

**Success Checklist:**
- [ ] GitHub trending fetcher works
- [ ] HackerNews top stories fetcher works
- [ ] RSS feed parser works
- [ ] All return consistent data format

#### Step 3: Build MCP Server with Tools

Create MCP server exposing data tools

```bash
# In server.py, create MCP tools:
# - get_github_trending(language, since)
# - get_hackernews_top(limit)
# - get_rss_feed(feed_url)
# - search_all(query) - searches across all sources
```

**Success Checklist:**
- [ ] MCP server class implemented
- [ ] All 4 tools defined and working
- [ ] Error handling added
- [ ] Response caching implemented

#### Step 4: Register and Test

Connect to Claude and test queries

```bash
# Add to ~/.claude/config.json
# Restart Claude Code
# Test: 'What's trending on GitHub in Python?'
# Test: 'Show me top HackerNews stories'
# Test: 'Search for AI news across all sources'
```

**Success Checklist:**
- [ ] MCP server registered
- [ ] Claude can call all tools
- [ ] Queries return real data
- [ ] Cross-source search works

### üéØ Success Criteria

- [ ] Claude can query multiple data sources through one MCP server
- [ ] Data is aggregated and searchable
- [ ] Caching improves performance
- [ ] You understand MCP tool creation

### üê∞ Next Steps (Optional)

Once you've completed the basics, try:

- Add more data sources (Reddit, Product Hunt, etc.)
- Implement trending topic detection
- Create scheduled data refresh
- Build summarization and insights

---

## Mission 3: Create a Long-Running Agent That Works Overnight

**‚è±Ô∏è Time:** 35-50 minutes  
**üìä Difficulty:** Intermediate  
**üõ†Ô∏è Tools:** Claude Code, Python, systemd/launchd

### üí° What You're Building

Build an autonomous agent that runs background tasks while you sleep and reports results in the morning.

**You'll have:**
- Autonomous agent that runs scheduled tasks
- Morning report delivered via email or dashboard
- Task queue system for background work
- Crash recovery and error logging

### ‚úÖ Prerequisites

- Python 3.8+ installed
- Access to system scheduler (cron/systemd/launchd)

### üöÄ Step-by-Step Instructions

**Execute these steps through Claude Code:**

#### Step 1: Create Agent Framework

Build the core agent structure

```bash
mkdir -p ~/ClawBoz/overnight-agent
cd ~/ClawBoz/overnight-agent
python3 -m venv .venv
source .venv/bin/activate
pip install schedule apscheduler
touch agent.py tasks.py config.json
```

**Success Checklist:**
- [ ] Project structure created
- [ ] Scheduling library installed
- [ ] Config file ready

#### Step 2: Implement Task System

Create task queue and executor

```bash
# In tasks.py, create:
# - Task base class with execute() method
# - TaskQueue with priority support
# - Built-in tasks: WebScraper, DataFetcher, Analyzer
# - Result logging to JSON
```

**Success Checklist:**
- [ ] Task base class works
- [ ] Task queue manages tasks
- [ ] At least 2 example tasks implemented
- [ ] Results are logged

#### Step 3: Add Scheduling and Error Handling

Make agent run reliably overnight

```bash
# In agent.py, add:
# - Scheduler that runs tasks at specified times
# - Crash recovery (restart on error)
# - Health checks and status logging
# - Graceful shutdown handling
```

**Success Checklist:**
- [ ] Scheduler runs tasks automatically
- [ ] Errors are caught and logged
- [ ] Agent restarts after crashes
- [ ] Status updates are visible

#### Step 4: Set Up System Service

Configure agent to run on boot

```bash
# For macOS (launchd):
# Create ~/Library/LaunchAgents/com.clawboz.agent.plist
# launchctl load ~/Library/LaunchAgents/com.clawboz.agent.plist
#
# For Linux (systemd):
# Create /etc/systemd/system/clawboz-agent.service
# systemctl enable clawboz-agent
# systemctl start clawboz-agent
```

**Success Checklist:**
- [ ] Service file created
- [ ] Agent starts on boot
- [ ] Can view logs
- [ ] Can stop/start/restart agent

#### Step 5: Create Morning Report

Generate and deliver daily summary

```bash
# Add report.py that:
# - Collects all overnight task results
# - Generates markdown summary
# - Saves to ~/ClawBoz/overnight-agent/reports/
# - (Optional) Emails or posts to dashboard
```

**Success Checklist:**
- [ ] Report generator works
- [ ] Summary includes all task results
- [ ] Report saved to file
- [ ] Can schedule report for 7am

### üéØ Success Criteria

- [ ] Agent runs continuously in background
- [ ] Tasks execute on schedule overnight
- [ ] Morning report shows completed work
- [ ] Agent survives crashes and reboots

### üê∞ Next Steps (Optional)

Once you've completed the basics, try:

- Add web dashboard for live monitoring
- Implement task dependencies (run B after A completes)
- Add notification system (Slack, Discord, SMS)
- Create task templates for common workflows

---

