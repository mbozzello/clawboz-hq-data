# üéØ ClawBoz Project Missions - 2026-02-18

**Today's hands-on projects:** 3 practical missions
**Sources:** Product Hunt, HackerNews, GitHub Trending, Lenny's Newsletter, Product Talk, Mind the Product
**Difficulty:** Mix of beginner to advanced

---

## Mission 1: Build an MCP Server to Pull Data from Multiple APIs

**‚è±Ô∏è Time:** 25-35 minutes  
**üìä Difficulty:** Beginner  
**üõ†Ô∏è Tools:** Claude Code, Python, MCP SDK

### üí° What You're Building

Create a unified MCP server that aggregates data from GitHub, HackerNews, and RSS feeds into Claude.

**You'll have:**
- Multi-source data aggregator MCP server
- Claude can query GitHub trends, HN top stories, and RSS feeds
- Unified search across all data sources
- Cached responses for faster queries

### ‚úÖ Prerequisites

- Python 3.8+ installed
- GitHub account (for API token)

### üöÄ Step-by-Step Instructions

**Execute these steps through Claude Code:**

#### Step 1: Create Project Structure

Set up the MCP server project

```bash
mkdir -p ~/ClawBoz/data-mcp
cd ~/ClawBoz/data-mcp
python3 -m venv .venv
source .venv/bin/activate
pip install mcp requests feedparser
touch server.py config.json
```

**Success Checklist:**
- [ ] Project directory created
- [ ] Virtual environment activated
- [ ] Dependencies installed

#### Step 2: Implement Data Source Connectors

Create functions to fetch from each API

```bash
# Ask Claude Code to create:
# - fetch_github_trending() - uses GitHub API
# - fetch_hackernews_top() - uses HN API
# - fetch_rss_feed(url) - parses any RSS feed
# All should return normalized JSON format
```

**Success Checklist:**
- [ ] GitHub trending fetcher works
- [ ] HackerNews top stories fetcher works
- [ ] RSS feed parser works
- [ ] All return consistent data format

#### Step 3: Build MCP Server with Tools

Create MCP server exposing data tools

```bash
# In server.py, create MCP tools:
# - get_github_trending(language, since)
# - get_hackernews_top(limit)
# - get_rss_feed(feed_url)
# - search_all(query) - searches across all sources
```

**Success Checklist:**
- [ ] MCP server class implemented
- [ ] All 4 tools defined and working
- [ ] Error handling added
- [ ] Response caching implemented

#### Step 4: Register and Test

Connect to Claude and test queries

```bash
# Add to ~/.claude/config.json
# Restart Claude Code
# Test: 'What's trending on GitHub in Python?'
# Test: 'Show me top HackerNews stories'
# Test: 'Search for AI news across all sources'
```

**Success Checklist:**
- [ ] MCP server registered
- [ ] Claude can call all tools
- [ ] Queries return real data
- [ ] Cross-source search works

### üéØ Success Criteria

- [ ] Claude can query multiple data sources through one MCP server
- [ ] Data is aggregated and searchable
- [ ] Caching improves performance
- [ ] You understand MCP tool creation

### üê∞ Next Steps (Optional)

Once you've completed the basics, try:

- Add more data sources (Reddit, Product Hunt, etc.)
- Implement trending topic detection
- Create scheduled data refresh
- Build summarization and insights

---

## Mission 2: Build a Codebase Analyzer with Claude MCP

**‚è±Ô∏è Time:** 30-40 minutes  
**üìä Difficulty:** Intermediate  
**üõ†Ô∏è Tools:** Claude Code, Python, Tree-sitter

### üí° What You're Building

Create an MCP server that analyzes any codebase and gives Claude deep insights about its structure, patterns, and complexity.

**You'll have:**
- Code analysis MCP server
- AST parsing for multiple languages
- Complexity metrics and code smells detection
- Dependency graph visualization

### ‚úÖ Prerequisites

- Python 3.8+ installed
- Git installed

### üöÄ Step-by-Step Instructions

**Execute these steps through Claude Code:**

#### Step 1: Set Up Analysis Environment

Install parsing and analysis tools

```bash
mkdir -p ~/ClawBoz/code-analyzer-mcp
cd ~/ClawBoz/code-analyzer-mcp
python3 -m venv .venv
source .venv/bin/activate
pip install mcp tree-sitter radon lizard gitpython
```

**Success Checklist:**
- [ ] Virtual environment created
- [ ] Tree-sitter installed for AST parsing
- [ ] Code metrics tools installed

#### Step 2: Implement Code Parsers

Create parsers for Python, JavaScript, TypeScript

```bash
# Create parsers.py with:
# - parse_python(file_path) - extracts functions, classes, imports
# - parse_javascript(file_path) - same for JS/TS
# - calculate_complexity(file_path) - cyclomatic complexity
# - detect_patterns(code) - find common patterns/anti-patterns
```

**Success Checklist:**
- [ ] Python parser extracts structure
- [ ] JavaScript/TypeScript parser works
- [ ] Complexity calculation accurate
- [ ] Pattern detection finds issues

#### Step 3: Build Analysis Tools

Create MCP tools for codebase insights

```bash
# In server.py, create tools:
# - analyze_file(path) - full file analysis
# - analyze_directory(path) - recursive analysis
# - find_complexity_hotspots(path) - high complexity files
# - get_dependency_graph(path) - import relationships
# - find_duplicates(path) - detect code duplication
```

**Success Checklist:**
- [ ] File analysis returns metrics
- [ ] Directory analysis works recursively
- [ ] Can identify complex code
- [ ] Dependency graph generated

#### Step 4: Test on Real Codebases

Analyze your own projects

```bash
# Register MCP server with Claude
# Ask Claude to:
# 'Analyze the ClawBoz dashboard codebase'
# 'Find the most complex functions'
# 'Show me the dependency graph'
# 'Detect any code smells or anti-patterns'
```

**Success Checklist:**
- [ ] Can analyze real codebases
- [ ] Metrics are accurate
- [ ] Insights are actionable
- [ ] Performance is acceptable

### üéØ Success Criteria

- [ ] Claude can analyze any codebase through MCP
- [ ] Complexity metrics are calculated correctly
- [ ] Pattern detection finds real issues
- [ ] You understand code analysis techniques

### üê∞ Next Steps (Optional)

Once you've completed the basics, try:

- Add more languages (Go, Rust, Java)
- Implement refactoring suggestions
- Create code quality dashboard
- Build automated PR review bot

---

## Mission 3: Create a Long-Running Agent That Works Overnight

**‚è±Ô∏è Time:** 35-50 minutes  
**üìä Difficulty:** Intermediate  
**üõ†Ô∏è Tools:** Claude Code, Python, systemd/launchd

### üí° What You're Building

Build an autonomous agent that runs background tasks while you sleep and reports results in the morning.

**You'll have:**
- Autonomous agent that runs scheduled tasks
- Morning report delivered via email or dashboard
- Task queue system for background work
- Crash recovery and error logging

### ‚úÖ Prerequisites

- Python 3.8+ installed
- Access to system scheduler (cron/systemd/launchd)

### üöÄ Step-by-Step Instructions

**Execute these steps through Claude Code:**

#### Step 1: Create Agent Framework

Build the core agent structure

```bash
mkdir -p ~/ClawBoz/overnight-agent
cd ~/ClawBoz/overnight-agent
python3 -m venv .venv
source .venv/bin/activate
pip install schedule apscheduler
touch agent.py tasks.py config.json
```

**Success Checklist:**
- [ ] Project structure created
- [ ] Scheduling library installed
- [ ] Config file ready

#### Step 2: Implement Task System

Create task queue and executor

```bash
# In tasks.py, create:
# - Task base class with execute() method
# - TaskQueue with priority support
# - Built-in tasks: WebScraper, DataFetcher, Analyzer
# - Result logging to JSON
```

**Success Checklist:**
- [ ] Task base class works
- [ ] Task queue manages tasks
- [ ] At least 2 example tasks implemented
- [ ] Results are logged

#### Step 3: Add Scheduling and Error Handling

Make agent run reliably overnight

```bash
# In agent.py, add:
# - Scheduler that runs tasks at specified times
# - Crash recovery (restart on error)
# - Health checks and status logging
# - Graceful shutdown handling
```

**Success Checklist:**
- [ ] Scheduler runs tasks automatically
- [ ] Errors are caught and logged
- [ ] Agent restarts after crashes
- [ ] Status updates are visible

#### Step 4: Set Up System Service

Configure agent to run on boot

```bash
# For macOS (launchd):
# Create ~/Library/LaunchAgents/com.clawboz.agent.plist
# launchctl load ~/Library/LaunchAgents/com.clawboz.agent.plist
#
# For Linux (systemd):
# Create /etc/systemd/system/clawboz-agent.service
# systemctl enable clawboz-agent
# systemctl start clawboz-agent
```

**Success Checklist:**
- [ ] Service file created
- [ ] Agent starts on boot
- [ ] Can view logs
- [ ] Can stop/start/restart agent

#### Step 5: Create Morning Report

Generate and deliver daily summary

```bash
# Add report.py that:
# - Collects all overnight task results
# - Generates markdown summary
# - Saves to ~/ClawBoz/overnight-agent/reports/
# - (Optional) Emails or posts to dashboard
```

**Success Checklist:**
- [ ] Report generator works
- [ ] Summary includes all task results
- [ ] Report saved to file
- [ ] Can schedule report for 7am

### üéØ Success Criteria

- [ ] Agent runs continuously in background
- [ ] Tasks execute on schedule overnight
- [ ] Morning report shows completed work
- [ ] Agent survives crashes and reboots

### üê∞ Next Steps (Optional)

Once you've completed the basics, try:

- Add web dashboard for live monitoring
- Implement task dependencies (run B after A completes)
- Add notification system (Slack, Discord, SMS)
- Create task templates for common workflows

---

