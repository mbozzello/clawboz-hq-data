# üéØ ClawBoz Project Missions - 2026-02-17

**Today's hands-on projects:** 3 practical missions

**Sources:** Product Hunt, HackerNews, GitHub Trending, Cursor Changelog

**Difficulty:** Mix of beginner to advanced


---


## Mission 1: Build Bluetooth Device Scanner with Privacy Alerts

**‚è±Ô∏è Time:** 35-45 minutes  
**üìä Difficulty:** Intermediate  
**üõ†Ô∏è Tools:** bleak, plyer, sqlite3


### üí° What You're Building

Scan nearby Bluetooth devices and alert when new trackers appear


**You'll have:**
- Real-time Bluetooth device scanner
- Database to track known vs new devices
- Desktop notifications for privacy alerts

### ‚úÖ Prerequisites

- Python 3.8+ installed
- Bluetooth adapter enabled

### üöÄ Step-by-Step Instructions

**Execute these steps through Claude Code:**


#### Step 1: Setup Scanner Environment

Install dependencies and create project structure

```bash
mkdir bluetooth-privacy-scanner && cd bluetooth-privacy-scanner
python -m venv venv && source venv/bin/activate
pip install bleak plyer asyncio sqlite3
touch scanner.py database.py main.py
```

**Success Checklist:**
- [ ] Virtual environment activated
- [ ] All packages installed successfully


#### Step 2: Create Device Database

Build SQLite database to track known devices

```bash
python -c "import sqlite3; db=sqlite3.connect('devices.db'); db.execute('CREATE TABLE devices (mac TEXT PRIMARY KEY, name TEXT, first_seen TIMESTAMP, last_seen TIMESTAMP)'); db.commit()"
echo 'Database created with devices table'
ls -la devices.db
```

**Success Checklist:**
- [ ] Database file exists
- [ ] Table structure created


#### Step 3: Build Scanner Logic

Create async Bluetooth scanner with device tracking

```bash
cat > scanner.py << 'EOF'
import asyncio
from bleak import BleakScanner
import sqlite3
from datetime import datetime
from plyer import notification

class BluetoothScanner:
    def __init__(self):
        self.db = sqlite3.connect('devices.db')
    
    async def scan_devices(self):
        devices = await BleakScanner.discover()
        for device in devices:
            self.check_device(device.address, device.name)
    
    def check_device(self, mac, name):
        cursor = self.db.cursor()
        existing = cursor.execute('SELECT * FROM devices WHERE mac=?', (mac,)).fetchone()
        if not existing:
            cursor.execute('INSERT INTO devices VALUES (?,?,?,?)', (mac, name, datetime.now(), datetime.now()))
            self.db.commit()
            notification.notify(title='New Bluetooth Device', message=f'Found: {name or mac}', timeout=5)
        else:
            cursor.execute('UPDATE devices SET last_seen=? WHERE mac=?', (datetime.now(), mac))
            self.db.commit()
EOF
python -c "from scanner import BluetoothScanner; print('Scanner module loaded')"
```

**Success Checklist:**
- [ ] Scanner module imports successfully
- [ ] Database connection works


#### Step 4: Create Main Runner

Build continuous scanning loop with interval control

```bash
cat > main.py << 'EOF'
import asyncio
from scanner import BluetoothScanner
import time

async def main():
    scanner = BluetoothScanner()
    print('Starting Bluetooth privacy scanner...')
    while True:
        try:
            await scanner.scan_devices()
            print(f'Scan completed at {time.strftime("%H:%M:%S")}')
            await asyncio.sleep(30)
        except KeyboardInterrupt:
            print('Scanner stopped')
            break

if __name__ == '__main__':
    asyncio.run(main())
EOF
python main.py &
sleep 60 && pkill -f main.py
```

**Success Checklist:**
- [ ] Scanner runs without errors
- [ ] Notifications appear for new devices
- [ ] Database updates with scan results


### üéØ Success Criteria

- [ ] Scanner detects nearby Bluetooth devices
- [ ] New device notifications trigger correctly
- [ ] Device history stored in database

### üê∞ Next Steps (Optional)

Once you've completed the basics, try:

- Add web dashboard for device history
- Implement device type classification
- Create geofencing alerts

*Inspired by: HackerNews: What your Bluetooth devices reveal*

---

## Mission 2: Build AI Agent Skill Validator Using Claude

**‚è±Ô∏è Time:** 40-50 minutes  
**üìä Difficulty:** Intermediate  
**üõ†Ô∏è Tools:** anthropic, pytest, json


### üí° What You're Building

Test and validate AI agent capabilities with automated scoring


**You'll have:**
- Automated skill testing framework
- Claude integration for task evaluation
- JSON report with capability scores

### ‚úÖ Prerequisites

- Anthropic API key
- Python 3.8+ with pip

### üöÄ Step-by-Step Instructions

**Execute these steps through Claude Code:**


#### Step 1: Setup Testing Framework

Create project structure and install Claude SDK

```bash
mkdir ai-skill-validator && cd ai-skill-validator
python -m venv venv && source venv/bin/activate
pip install anthropic pytest pytest-json-report
touch validator.py tests.py config.json
```

**Success Checklist:**
- [ ] Project directory created
- [ ] Anthropic SDK installed


#### Step 2: Create Skill Test Suite

Build tests for common AI agent capabilities

```bash
cat > tests.py << 'EOF'
import json
from validator import SkillValidator

class TestAgentSkills:
    def __init__(self):
        self.validator = SkillValidator()
    
    def test_code_generation(self):
        task = "Write a Python function to calculate fibonacci numbers"
        score = self.validator.evaluate_task(task, "coding")
        assert score >= 0.7, f"Code generation failed: {score}"
    
    def test_data_analysis(self):
        task = "Analyze this CSV data and identify trends: sales,month\n100,Jan\n150,Feb\n120,Mar"
        score = self.validator.evaluate_task(task, "analysis")
        assert score >= 0.6, f"Data analysis failed: {score}"
    
    def test_creative_writing(self):
        task = "Write a haiku about artificial intelligence"
        score = self.validator.evaluate_task(task, "creative")
        assert score >= 0.5, f"Creative writing failed: {score}"
EOF
echo 'Test suite created with 3 skill categories'
```

**Success Checklist:**
- [ ] Test file contains multiple skill tests
- [ ] Test structure follows pytest format


#### Step 3: Build Validator Core

Create Claude-powered evaluation system

```bash
cat > validator.py << 'EOF'
import anthropic
import json
import os

class SkillValidator:
    def __init__(self):
        self.client = anthropic.Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))
    
    def evaluate_task(self, task, category):
        try:
            response = self.client.messages.create(
                model="claude-3-haiku-20240307",
                max_tokens=1000,
                messages=[{"role": "user", "content": f"Complete this {category} task: {task}"}]
            )
            result = response.content[0].text
            return self.score_response(result, category)
        except Exception as e:
            return 0.0
    
    def score_response(self, response, category):
        scoring_prompt = f"Rate this {category} response from 0-1: {response[:500]}..."
        try:
            score_response = self.client.messages.create(
                model="claude-3-haiku-20240307",
                max_tokens=50,
                messages=[{"role": "user", "content": scoring_prompt + " Return only a number between 0 and 1."}]
            )
            return float(score_response.content[0].text.strip())
        except:
            return 0.5
EOF
export ANTHROPIC_API_KEY='your-key-here'
python -c "from validator import SkillValidator; print('Validator ready')"
```

**Success Checklist:**
- [ ] Validator class loads successfully
- [ ] API key environment variable set


#### Step 4: Run Validation Tests

Execute skill tests and generate capability report

```bash
pytest tests.py --json-report --json-report-file=skill_report.json -v
cat > report_generator.py << 'EOF'
import json

with open('skill_report.json', 'r') as f:
    data = json.load(f)

results = {
    'total_tests': data['summary']['total'],
    'passed': data['summary']['passed'],
    'failed': data['summary']['failed'],
    'success_rate': data['summary']['passed'] / data['summary']['total'] * 100
}

print(json.dumps(results, indent=2))
EOF
python report_generator.py > final_report.json
cat final_report.json
```

**Success Checklist:**
- [ ] Tests execute without crashes
- [ ] JSON report generated
- [ ] Success rate calculated


### üéØ Success Criteria

- [ ] All skill tests run and produce scores
- [ ] Claude evaluates responses automatically
- [ ] JSON report shows capability breakdown

### üê∞ Next Steps (Optional)

Once you've completed the basics, try:

- Add more skill categories
- Create comparative benchmarking
- Build web interface for results

*Inspired by: HackerNews: Study: Self-generated Agent Skills are useless*

---

## Mission 3: Build Media Request Bot for Jellyfin/Plex

**‚è±Ô∏è Time:** 45-60 minutes  
**üìä Difficulty:** Advanced  
**üõ†Ô∏è Tools:** discord.py, requests, tmdbsimple


### üí° What You're Building

Automate media requests with AI-powered content discovery


**You'll have:**
- Discord bot for media requests
- TMDB integration for content lookup
- Auto-request to Jellyfin/Plex systems

### ‚úÖ Prerequisites

- Discord bot token
- TMDB API key

### üöÄ Step-by-Step Instructions

**Execute these steps through Claude Code:**


#### Step 1: Setup Bot Framework

Create Discord bot with media request commands

```bash
mkdir media-request-bot && cd media-request-bot
python -m venv venv && source venv/bin/activate
pip install discord.py requests tmdbsimple python-dotenv
touch bot.py media_handler.py .env
```

**Success Checklist:**
- [ ] Discord.py installed successfully
- [ ] Project structure created


#### Step 2: Build Media Lookup

Create TMDB integration for content discovery

```bash
cat > media_handler.py << 'EOF'
import tmdbsimple as tmdb
import requests
import os

class MediaHandler:
    def __init__(self):
        tmdb.API_KEY = os.getenv('TMDB_API_KEY')
        self.jellyfin_url = os.getenv('JELLYFIN_URL')
        self.jellyfin_token = os.getenv('JELLYFIN_TOKEN')
    
    def search_movie(self, query):
        search = tmdb.Search()
        response = search.movie(query=query)
        if response['results']:
            movie = response['results'][0]
            return {
                'title': movie['title'],
                'year': movie['release_date'][:4] if movie['release_date'] else 'Unknown',
                'overview': movie['overview'][:200] + '...' if len(movie['overview']) > 200 else movie['overview'],
                'tmdb_id': movie['id']
            }
        return None
    
    def request_media(self, media_info):
        # Simulate request to media server
        print(f"Requesting: {media_info['title']} ({media_info['year']})")
        return True
EOF
echo 'TMDB_API_KEY=your-tmdb-key' > .env
python -c "from media_handler import MediaHandler; print('Media handler ready')"
```

**Success Checklist:**
- [ ] TMDB search function works
- [ ] Media handler class loads


#### Step 3: Create Discord Bot

Build bot with slash commands for media requests

```bash
cat > bot.py << 'EOF'
import discord
from discord.ext import commands
from media_handler import MediaHandler
import os
from dotenv import load_dotenv

load_dotenv()

bot = commands.Bot(command_prefix='!', intents=discord.Intents.default())
media = MediaHandler()

@bot.event
async def on_ready():
    print(f'{bot.user} is ready for media requests!')

@bot.slash_command(name='request', description='Request a movie or TV show')
async def request_media(ctx, title: str):
    await ctx.defer()
    
    result = media.search_movie(title)
    if result:
        embed = discord.Embed(
            title=f"{result['title']} ({result['year']})",
            description=result['overview'],
            color=0x00ff00
        )
        
        if media.request_media(result):
            embed.add_field(name="Status", value="‚úÖ Request submitted", inline=False)
        else:
            embed.add_field(name="Status", value="‚ùå Request failed", inline=False)
            
        await ctx.followup.send(embed=embed)
    else:
        await ctx.followup.send("‚ùå Could not find that title. Please try again.")

bot.run(os.getenv('DISCORD_BOT_TOKEN'))
EOF
echo 'DISCORD_BOT_TOKEN=your-bot-token' >> .env
```

**Success Checklist:**
- [ ] Bot code structure complete
- [ ] Slash commands defined


#### Step 4: Test Bot Integration

Run bot and test media request functionality

```bash
python -c "import discord; print('Discord.py version:', discord.__version__)"
echo 'Starting bot in test mode...'
timeout 30 python bot.py || echo 'Bot test completed'
echo 'Bot setup complete - ready for deployment'
```

**Success Checklist:**
- [ ] Bot starts without errors
- [ ] Commands register successfully
- [ ] TMDB integration working


### üéØ Success Criteria

- [ ] Discord bot responds to slash commands
- [ ] Movie/TV search returns accurate results
- [ ] Request system logs submissions

### üê∞ Next Steps (Optional)

Once you've completed the basics, try:

- Add approval workflow with reactions
- Integrate with actual Plex/Jellyfin APIs
- Add user permission management

*Inspired by: GitHub Trending: seerr-team/seerr*

---

---

## Mission 4: Build WiFi Human Pose Tracker with Alert System

**‚è±Ô∏è Time:** 45-60 minutes  
**üìä Difficulty:** Advanced  
**üõ†Ô∏è Tools:** Python, OpenCV, FastAPI


### üí° What You're Building

Create a real-time human pose detection system using WiFi signals and Python.


**You'll have:**
- WiFi signal analysis for human detection
- Real-time pose estimation pipeline
- Web dashboard with alerts

### ‚úÖ Prerequisites

- Python 3.8+ installed
- Basic networking knowledge

### üöÄ Step-by-Step Instructions

**Execute these steps through Claude Code:**


#### Step 1: Setup WiFi monitoring

Install dependencies and create WiFi signal capture script.

```bash
pip install scapy opencv-python fastapi uvicorn numpy scipy
mkdir wifi-pose-tracker && cd wifi-pose-tracker
touch wifi_monitor.py pose_detector.py app.py
sudo setcap cap_net_raw+eip $(which python3)
python -c "import scapy; print('Scapy ready')"
```

**Success Checklist:**
- [ ] All packages installed successfully
- [ ] Network permissions granted
- [ ] Project structure created


#### Step 2: Build pose estimation

Create WiFi signal processing and pose detection algorithms.

```bash
curl -o pose_detector.py https://raw.githubusercontent.com/opencv/opencv/master/samples/python/pose_estimation.py
python -c "import cv2; print('OpenCV version:', cv2.__version__)"
touch signal_processor.py
echo 'from scapy.all import *' > wifi_monitor.py
```

**Success Checklist:**
- [ ] OpenCV working correctly
- [ ] Signal processing module ready
- [ ] Pose detection template loaded


#### Step 3: Create web dashboard

Build FastAPI dashboard to visualize poses and send alerts.

```bash
echo 'from fastapi import FastAPI' > app.py
mkdir templates static
touch templates/index.html static/style.css
uvicorn app:app --reload --port 8000 &
curl -s http://localhost:8000 || echo 'Server starting...'
```

**Success Checklist:**
- [ ] FastAPI server running
- [ ] Dashboard accessible
- [ ] Static files served


#### Step 4: Test and deploy

Run complete system and verify pose tracking works.

```bash
python wifi_monitor.py --interface wlan0 &
python pose_detector.py --source wifi &
curl -X POST http://localhost:8000/detect
pkill -f 'python.*wifi_monitor'
```

**Success Checklist:**
- [ ] WiFi monitoring active
- [ ] Pose detection running
- [ ] API endpoints responding


### üéØ Success Criteria

- [ ] WiFi signals being captured and processed
- [ ] Pose coordinates displayed in dashboard
- [ ] Alert system triggers on movement

### üê∞ Next Steps (Optional)

Once you've completed the basics, try:

- Add ML model for better accuracy
- Integrate with home automation
- Deploy to Raspberry Pi

*Inspired by: ruvnet/wifi-densepose - WiFi-based human pose estimation*

---

## Mission 5: Build AI Code Review Bot for GitHub PRs

**‚è±Ô∏è Time:** 30-45 minutes  
**üìä Difficulty:** Intermediate  
**üõ†Ô∏è Tools:** Node.js, GitHub API, OpenAI


### üí° What You're Building

Create an automated code reviewer that analyzes PRs with team context.


**You'll have:**
- GitHub webhook listener for PRs
- AI-powered code analysis engine
- Automated comment posting system

### ‚úÖ Prerequisites

- Node.js 18+ installed
- GitHub personal access token

### üöÄ Step-by-Step Instructions

**Execute these steps through Claude Code:**


#### Step 1: Setup GitHub integration

Create Node.js app with GitHub API and webhook handling.

```bash
mkdir ai-code-reviewer && cd ai-code-reviewer
npm init -y && npm install @octokit/rest express dotenv openai
touch index.js .env webhook.js
echo 'GITHUB_TOKEN=your_token' > .env
echo 'OPENAI_API_KEY=your_key' >> .env
```

**Success Checklist:**
- [ ] NPM dependencies installed
- [ ] Environment variables configured
- [ ] Project structure ready


#### Step 2: Build code analyzer

Create AI service that analyzes code changes and generates reviews.

```bash
touch analyzer.js reviewer.js
echo 'const { OpenAI } = require("openai");' > analyzer.js
node -e "console.log('Testing OpenAI...'); require('openai');"
curl -s https://api.github.com/user -H 'Authorization: token your_token'
```

**Success Checklist:**
- [ ] OpenAI client initialized
- [ ] GitHub API accessible
- [ ] Code analysis logic ready


#### Step 3: Create PR webhook handler

Set up Express server to receive and process GitHub PR events.

```bash
echo 'const express = require("express");' > index.js
node index.js &
curl -X POST http://localhost:3000/webhook -H 'Content-Type: application/json'
ngrok http 3000 --log=stdout > ngrok.log &
```

**Success Checklist:**
- [ ] Express server running
- [ ] Webhook endpoint responding
- [ ] Public URL available via ngrok


#### Step 4: Test with real PR

Deploy bot and test with actual GitHub pull request.

```bash
curl -X POST https://api.github.com/repos/user/repo/hooks
git init test-repo && cd test-repo
echo 'console.log("test");' > test.js && git add . && git commit -m 'test'
gh pr create --title 'Test PR' --body 'Testing AI reviewer'
```

**Success Checklist:**
- [ ] GitHub webhook configured
- [ ] Test PR created successfully
- [ ] Bot analyzing and commenting


### üéØ Success Criteria

- [ ] Bot receives PR webhook events
- [ ] AI generates meaningful code reviews
- [ ] Comments posted automatically to PRs

### üê∞ Next Steps (Optional)

Once you've completed the basics, try:

- Add team-specific context learning
- Implement security vulnerability detection
- Create dashboard for review metrics

*Inspired by: Unblocked AI Code Review - context-aware PR reviews*

---

## Mission 6: Build Voice-to-Code Dictation Tool

**‚è±Ô∏è Time:** 35-50 minutes  
**üìä Difficulty:** Intermediate  
**üõ†Ô∏è Tools:** Python, SpeechRecognition, OpenAI


### üí° What You're Building

Create a speech-to-code system that converts voice commands to working code.


**You'll have:**
- Real-time speech recognition system
- Voice-to-code AI transformer
- Live code editor with voice input

### ‚úÖ Prerequisites

- Python 3.8+ with microphone access
- OpenAI API key configured

### üöÄ Step-by-Step Instructions

**Execute these steps through Claude Code:**


#### Step 1: Setup speech recognition

Install dependencies and configure microphone input capture.

```bash
pip install speechrecognition pyaudio openai streamlit pydub
mkdir voice-to-code && cd voice-to-code
touch speech_engine.py code_generator.py app.py
python -c "import speech_recognition as sr; print('Speech recognition ready')"
python -m speech_recognition
```

**Success Checklist:**
- [ ] Speech recognition library working
- [ ] Microphone access granted
- [ ] Audio processing ready


#### Step 2: Build voice-to-code AI

Create OpenAI integration that converts speech to executable code.

```bash
echo 'import openai' > code_generator.py
touch prompts.py voice_commands.json
python -c "from openai import OpenAI; print('OpenAI client ready')"
echo '{"create_function": "def {name}():"}' > voice_commands.json
```

**Success Checklist:**
- [ ] OpenAI API connection established
- [ ] Voice command mappings loaded
- [ ] Code generation pipeline ready


#### Step 3: Create live editor interface

Build Streamlit app with real-time voice input and code output.

```bash
echo 'import streamlit as st' > app.py
streamlit run app.py &
curl -s http://localhost:8501
touch live_editor.py syntax_highlighter.py
```

**Success Checklist:**
- [ ] Streamlit interface running
- [ ] Live editor accessible
- [ ] Voice input button functional


#### Step 4: Test voice coding workflow

Record voice commands and verify code generation works end-to-end.

```bash
python speech_engine.py --test-mic
echo 'create a function that adds two numbers' | python code_generator.py
python -c "exec(open('generated_code.py').read())"
streamlit run app.py --server.port 8502
```

**Success Checklist:**
- [ ] Voice commands recognized accurately
- [ ] Generated code executes successfully
- [ ] Full workflow working in browser


### üéØ Success Criteria

- [ ] Voice commands converted to working code
- [ ] Real-time speech recognition functioning
- [ ] Generated code executes without errors

### üê∞ Next Steps (Optional)

Once you've completed the basics, try:

- Add support for more programming languages
- Implement code refactoring commands
- Create VSCode extension integration

*Inspired by: Wispr Flow - 4x faster voice dictation tool*

---